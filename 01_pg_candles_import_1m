# 01_pg_candles_import_1m.py
# Descarga velas OHLCV de 1 minuto para s√≠mbolos activos y las almacena en la tabla ohlcv_raw_1m.
# Ahora los campos timestamp y timestamp_col son VARCHAR(30) y se insertan como cadenas ISO8601.

import time
import ccxt
import psycopg2
from sqlalchemy import create_engine
import pandas as pd
from datetime import datetime, timedelta
import pytz
import math

from parmspg import API_KEY, API_SECRET, API_PASSPHRASE, DB_HOST, DB_PORT, DB_USER, DB_PASSWORD, DB_NAME

# Par√°metros de la API Bitget
LIMIT_PER_FETCH = 200
RATE_LIMIT_SECONDS = 1.2
DAYS_PER_BATCH = 3

TIMEFRAME_STR = '1m'
TIMEFRAME_MIN = 1

try:
    exchange = ccxt.bitget({
        'apiKey': API_KEY,
        'secret': API_SECRET,
        'password': API_PASSPHRASE,
        'enableRateLimit': True,
        'options': {
            'defaultType': 'swap',
            'adjustForTimeZone': False,
        }
    })
    exchange.load_markets()
    print("Conexi√≥n con CCXT (Bitget) establecida y mercados cargados.")
except Exception as e:
    print(f"Error al inicializar CCXT con Bitget: {e}")
    exit()

try:
    conn = psycopg2.connect(
        host=DB_HOST,
        port=DB_PORT,
        user=DB_USER,
        password=DB_PASSWORD,
        database=DB_NAME
    )
    cursor = conn.cursor()
    cursor.execute("SET TIME ZONE 'UTC'")
    print("Conexi√≥n a PostgreSQL establecida y configurada en UTC.")

    engine = create_engine(f'postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}')
except psycopg2.Error as err:
    print(f"Error al conectar o configurar PostgreSQL: {err}")
    exit()
except UnicodeDecodeError as ude:
    print(f"Error de codificaci√≥n en las credenciales: {ude}")
    exit()

def fetch_ohlcv_1m(symbol_for_api, since_ts, until_ts):
    all_data = []
    ts = since_ts
    params = {'type': 'swap'}
    while ts < until_ts:
        try:
            bars = exchange.fetch_ohlcv(symbol_for_api, TIMEFRAME_STR, since=ts, limit=LIMIT_PER_FETCH, params=params)
        except ccxt.RateLimitExceeded as e:
            print(f"[{symbol_for_api}] L√≠mite de tasa excedido, esperando 60s... {e}")
            time.sleep(60)
            continue
        except ccxt.NetworkError as e:
            print(f"[{symbol_for_api}] Error de red: {e}. Reintentando en 10s...")
            time.sleep(10)
            continue
        except ccxt.ExchangeError as e:
            print(f"[{symbol_for_api}] Error del exchange: {e}. Saltando fetch para este rango.")
            break
        except Exception as e:
            print(f"[{symbol_for_api}] Error inesperado al traer datos: {e}. Reintentando en 5s...")
            time.sleep(5)
            continue

        if not bars:
            break

        newest_ts_in_batch = bars[-1][0]
        added_count = 0
        for bar in bars:
            ts_api = bar[0]
            o, h, l, c, v = bar[1:]
            time_utc_w = datetime.fromtimestamp(ts_api / 1000, tz=pytz.UTC)
            time_bogota = time_utc_w.astimezone(pytz.timezone('America/Bogota'))

            bar_struct = {
                'ticker': None,  # se llenar√° luego
                'timestamp': time_utc_w,
                'timestamp_col': time_bogota,
                'yyyy': time_utc_w.year,
                'mm': time_utc_w.month,
                'dd': time_utc_w.day,
                'hh': time_utc_w.hour,
                'open': float(o) if o is not None else 0.0,
                'high': float(h) if h is not None else 0.0,
                'low': float(l) if l is not None else 0.0,
                'close': float(c) if c is not None else 0.0,
                'volume': float(v) if v is not None else 0.0,
                'ts_api': ts_api  # solo para debug opcional
            }

            if ts_api >= until_ts:
                continue
            if ts_api >= ts:
                all_data.append(bar_struct)
                added_count += 1

        if added_count == 0 or newest_ts_in_batch < ts:
            break

        ts = newest_ts_in_batch + 1
        time.sleep(RATE_LIMIT_SECONDS)

    return all_data

def store_ohlcv_1m(symbol_in_db, bars, start_dt_req, end_dt_req):
    if not bars:
        return 0

    start_ts_req = int(start_dt_req.timestamp() * 1000)
    end_ts_req = int(end_dt_req.timestamp() * 1000)

    records = []
    for bar_struct in bars:
        ts_api = bar_struct['ts_api']
        if ts_api < start_ts_req or ts_api >= end_ts_req:
            continue
        rec = dict(bar_struct)
        rec['ticker'] = symbol_in_db
        records.append(rec)

    if not records:
        return 0

    df = pd.DataFrame(records)

    # SOLO columnas v√°lidas para la tabla (quita ts_api y cualquier otra)
    cols_validos = ['ticker', 'timestamp', 'timestamp_col', 'yyyy', 'mm', 'dd', 'hh', 'open', 'high', 'low', 'close', 'volume']
    df = df[cols_validos]

    # Convierte los datetime a string ISO8601, m√°ximo 30 caracteres (ej: '2023-01-01T00:00:00+00:00')
    df['timestamp'] = df['timestamp'].apply(lambda x: x.isoformat())
    df['timestamp_col'] = df['timestamp_col'].apply(lambda x: x.isoformat())

    try:
        df.to_sql(
            'ohlcv_raw_1m',
            engine,
            if_exists='append',
            index=False,
            method='multi',
            schema=None,
            chunksize=1000
        )
        inserted_count = len(df)
        return inserted_count
    except Exception as err:
        print(f"[{symbol_in_db}] Error al insertar en BD ohlcv_raw_1m: {err}")
        print("Primer registro (si existe):", records[0] if records else "N/A")
        conn.rollback()
        return -1

def procesar_rango_1m(symbol_in_db, start_dt, end_dt):
    start_dt = start_dt.replace(tzinfo=pytz.UTC)
    end_dt = end_dt.replace(tzinfo=pytz.UTC)

    parts = symbol_in_db.split('/')
    if len(parts) == 2:
        base = parts[0]
        quote = parts[1]
        symbol_for_api = f"{base}/{quote}:{quote}"
    else:
        print(f"Error: Formato de ticker inesperado en la BD: {symbol_in_db}. No se puede construir s√≠mbolo API.")
        return

    print(f"üîπ {symbol_in_db} ({symbol_for_api}) - 1m: {start_dt.strftime('%Y-%m-%d %H:%M')} ‚Üí {end_dt.strftime('%Y-%m-%d %H:%M')}")
    since_ts = int(start_dt.timestamp() * 1000)
    until_ts = int(end_dt.timestamp() * 1000)

    bars = fetch_ohlcv_1m(symbol_for_api, since_ts, until_ts)
    if not bars:
        print(f"   ‚ö†Ô∏è Sin datos obtenidos para {symbol_in_db} en este rango.")
        return

    total_inserted = store_ohlcv_1m(symbol_in_db, bars, start_dt, end_dt)
    if total_inserted == -1:
        print(f"   ‚ùå Error al guardar velas para {symbol_in_db} - 1m.")
    elif total_inserted == 0 and bars:
        print(f"   ‚ÑπÔ∏è No se insertaron velas nuevas (posiblemente ya exist√≠an) para {symbol_in_db} - 1m.")
    elif total_inserted > 0:
        print(f"   ‚úÖ {total_inserted} registros afectados en BD para {symbol_in_db} - 1m.")
    else:
        print(f"   ? Situaci√≥n inesperada para {symbol_in_db} - 1m.")

def main():
    global conn, cursor, engine
    try:
        cursor.execute("SELECT ticker FROM tickers WHERE activo = true")
        symbols_in_db = [row[0] for row in cursor.fetchall()]
        if not symbols_in_db:
            print("No hay tickers activos encontrados en la tabla 'tickers'. Finalizando.")
            return
        print(f"Tickers base a procesar: {symbols_in_db}")

        year_start_dt = datetime(2023, 1, 1, 0, 0, 0, tzinfo=pytz.UTC)
        year_end_dt = datetime(2024, 1, 1, 0, 0, 0, tzinfo=pytz.UTC)

        total_days = (year_end_dt - year_start_dt).days
        if total_days <= 0:
            print("Error: La fecha de fin debe ser posterior a la fecha de inicio.")
            return
        total_batches = math.ceil(total_days / DAYS_PER_BATCH)
        print(f"Procesando rango de fechas: {year_start_dt.strftime('%Y-%m-%d')} a {(year_end_dt - timedelta(days=1)).strftime('%Y-%m-%d')}")
        print(f"Total d√≠as: {total_days}, Lotes de {DAYS_PER_BATCH} d√≠as, Total Lotes: {total_batches}.")

        current_batch_start_dt = year_start_dt
        batch_num = 0

        while current_batch_start_dt < year_end_dt:
            batch_num += 1
            current_batch_end_dt = current_batch_start_dt + timedelta(days=DAYS_PER_BATCH)
            if current_batch_end_dt > year_end_dt:
                current_batch_end_dt = year_end_dt

            print(f"\n--- Procesando Lote {batch_num}/{total_batches} ({current_batch_start_dt.strftime('%Y-%m-%d')} a {(current_batch_end_dt - timedelta(microseconds=1)).strftime('%Y-%m-%d %H:%M')}) ---")

            for symbol_db in symbols_in_db:
                print(f"\n Procesando S√≠mbolo DB: {symbol_db}")
                try:
                    procesar_rango_1m(symbol_db, current_batch_start_dt, current_batch_end_dt)
                    time.sleep(0.5)
                except Exception as e:
                    print(f"!! Error INESPERADO procesando {symbol_db} en lote {batch_num}: {e}")
                    import traceback
                    traceback.print_exc()

            try:
                print(f"\n--- Fin Lote {batch_num}/{total_batches}. Realizando COMMIT. ---")
                conn.commit()
            except psycopg2.Error as err:
                print(f"!! Error al realizar COMMIT para el lote {batch_num}: {err}")
                print("Intentando rollback...")
                conn.rollback()

            current_batch_start_dt = current_batch_end_dt
            time.sleep(2)

        print(f"\nProceso completado para el rango de fechas definido.")

    except psycopg2.Error as err:
        print(f"Error de PostgreSQL durante la ejecuci√≥n principal: {err}")
    except ccxt.AuthenticationError as e:
        print(f"Error de autenticaci√≥n con Bitget: {e}. Verifica tus credenciales API en parmspg.py")
    except ccxt.ExchangeNotAvailable as e:
        print(f"Error: Exchange Bitget no disponible o problemas de conexi√≥n: {e}")
    except Exception as e:
        print(f"Error inesperado en main: {e}")
        import traceback
        traceback.print_exc()
    finally:
        if locals().get('cursor'):
            try:
                cursor.close()
                print("Cursor de PostgreSQL cerrado.")
            except:
                pass
        if locals().get('conn') and conn:
            try:
                conn.close()
                print("Conexi√≥n a PostgreSQL cerrada.")
            except:
                pass
        if locals().get('engine'):
            try:
                engine.dispose()
                print("Motor SQLAlchemy cerrado.")
            except:
                pass

if __name__ == '__main__':
    main()
# 01_pg_candles_import_1m.py
# Descarga velas OHLCV de 1 minuto para s√≠mbolos activos y las almacena en la tabla ohlcv_raw_1m.
# Ahora los campos timestamp y timestamp_col son VARCHAR(30) y se insertan como cadenas ISO8601.
